
#Assignment Name: HW 7
#Student Name: Mo Pei

#Problem One
# (a)
#chi square is degree of freedome is two and also is exponential distribution with mean of 2
#sum of n chi quare of r degree freedom is chi square distribution with nr degress freedom.
n <- 3
N <- 10^4
y <- matrix(0,N,n)
for (j in 1:n){
  e <- numeric(N)
  for (i in 1:N) {
    e[i] <- rexp(100,1/2)
  }
  y[,j] <- e
}

# adding three chi square degree freedom 
z <- rowSums(y)
hist(z, breaks= "FD", probability = TRUE)
curve(dchisq(x,6), col = "red", add = TRUE)



# (b)
N<- 10^4
unif.mean <- numeric(N)
for (i in 1:N){
  unif.mean[i] <- mean(runif(50,0,1))
}

standard_norm<-(unif.mean-mean(unif.mean))/sd(unif.mean)
t_new<-standard_norm/sqrt(z/6)

hist(t_new, breaks= "FD", probability = TRUE)
curve(dt(x,6), col = "red", add = TRUE)


#Problem Two

#gamma function
my.gamma<-Vectorize(function(r) integrate(function(x) x^(r-1)*exp(-x), 0, Inf)$val)

# t-density function from page 388 
my.t <- Vectorize(function(t,k) my.gamma((k+1)/2)/ (sqrt(k*pi) * my.gamma(k/2) * (1+(t^2)/k)^((k+1)/2)) )

# four degree freedom
curve(my.t(x,4), col = "green",xlim=c(-2,2))
curve(dt(x,4), col = "brown",xlim=c(-2,2), lty = 2, add = TRUE)

# five degree freedom
curve(my.t(x,5), col = "green",xlim=c(-2,2))
curve(dt(x,5), col = "brown",xlim=c(-2,2), lty = 2, add = TRUE)

k<-5
N <- 50000
vars <- numeric(N)
moment_4 <- numeric(N)
for (i in 1:N) {
  x <- rt(100,k)
  vars[i] <- var(x)
  moment_4[i] <- mean(x^4)
}


#plot 4th moments
hist(moment_4)
# plot obs and expected variance
hist(vars, breaks="FD",xlim=c(0,10))
abline(v = k/(k-2), col = "red", lty = 2);
var_mean <- mean(vars)
var_theory <- k/(k-2)
var_mean
# 1.667581
var_theory
# 1.666667
# So theory variance closes to simulation variance 


#Problem Three

N<-5000; 
mean_square <- numeric(N)
vars <- numeric(N)
for (i in 1:N) {
  x <- runif(6,-1,1)
  mean_square[i] <- mean(x)^2
  vars[i] <- var(x)
}
plot(mean_square,vars)
cor(mean_square, vars)

# correlation coefficent is -0.3164728 and so there is a negative relationship between mean square and 
# variance. 

# anecdotal situations
extreme <- c(-1, -1.2, -1.03, -1.97, -1.9, -.99)
extreme_mean_square <- mean(extreme)^2
extreme_var <- var(extreme)
extreme_mean_square; extreme_var
# 1.818003, 0.2127767

extreme <- c(-0.1, 0.2, -.03, .07, -.09, .09)
extreme_mean_square <- mean(extreme)^2
extreme_var <- var(extreme)
extreme_mean_square; extreme_var
# 0.0005444444, 0.01374667

# from an extreme case that all points concentrate on -1 to 0
# the variance is 0.21 to 0.01. So it shows when square of mean increases
# the variance decreases.




# Problem four
NCBirths2004 <- read.csv("C:/Users/Mo.Pei/Desktop/156/Data/NCBirths2004.csv")

# (a)
weight<-NCBirths2004$Weight
N <- 10^3
mean_square <- numeric(N)
for (i in 1:N) {
  x <- sample(weight,6)
  y <- (x - mean(weight))/sqrt(var(weight))
  mean_square[i] <- y^2 * 6
}
hist(mean_square, breaks= "FD", probability = TRUE)
curve(dchisq(x,1), col = "red", add = TRUE)

# not closely followed chi square with 1 degree freedom


# (b)
N <- 10^3
sum_square <- numeric(N)
for (i in 1:N) {
  x <- sample(weight,6)
  y <- (x - mean(weight))/sqrt(var(weight))
  sum_square[i] <- sum(y^2) 
}
hist(sum_square, breaks= "FD", probability = TRUE)
curve(dchisq(x,6), col = "red", add = TRUE)

# It fits better for chi sq degree freedom of 6 then problem a


# (c)
N <- 10^3
sample_var <- numeric(N)
for (i in 1:N) {
  x <- sample(weight,6)
  y <- (x - mean(weight))/sqrt(var(weight))
  sample_var[i] <- var(y)*5
}
hist(sample_var, breaks= "FD", probability = TRUE)
curve(dchisq(x,5), col = "red", add = TRUE)

# It fits better for chi sq degree freedom of 5

# (d)
N <- 10^3
sample_var <- numeric(N)
square_mean<- numeric(N)
for (i in 1:N) {
  x <- sample(weight,6)
  y <- (x - mean(weight))/sqrt(var(weight))
  sample_var[i] <- var(y)
  square_mean[i] <-(mean(y))^0.5
}
plot(square_mean,sample_var)
cor.test(square_mean, sample_var)

# with correlation coefficient of 0.155. 
# they are almost uncorrelated 

# (e)
N <- 10^3
sample_sd <- numeric(N)
sample_mean<- numeric(N)
mean_sd_ratio <- numeric(N)
for (i in 1:N) {
  x <- sample(weight,6)
  y <- (x - mean(weight))/sqrt(var(weight))
  sample_sd[i] <- sd(y)
  sample_mean[i] <-mean(y)
  mean_sd_ratio[i]<- sample_mean[i] / sample_sd[i] 
}
hist(mean_sd_ratio, breaks= "FD", probability = TRUE)
curve(dchisq(x,5), col = "red", add = TRUE)


# It dose not follow chi square with degree freedom of 5



#Problem Five
# If population's sigma is known
L <- 18.05 + qnorm(0.05) * 5/sqrt(20) #usually less than the true mean
U <- 18.05 + qnorm(0.95) * 5/sqrt(20) #usually greater than the true mean
L;U
# 90% confidence interval is between 16.211 and 19.889 

# If population's sigma is not known, use sample's standard deviation
counter <- 0
plot(x =c(11,25), y = c(1,100), type = "n", xlab = "", ylab = "") #blank plot
for (i in 1:1000) {
  x <-rnorm(20, 18.05, 5) #random sample
  L <- mean(x) + qt(0.05, 19) * sd(x)/sqrt(20) #usually less than the true mean
  U <- mean(x) + qt(0.95, 19) * sd(x)/sqrt(20) #usually greater than the true mean
  if (L < 18.05 && U > 18.05) counter <- counter + 1 #count +1 if we were correct
  if(i <= 100) segments(L, i, U, i)
}
abline (v = 18.05, col = "red") #vertical line at true mean
counter/1000 #what fraction of the time did our confidence interval include the true mean?
# 0.903
qt(c(0.05, .95), 19) #quantiles are more than 2 standard deviations
-1.729133  1.729133
# As expected T confidence interval has probablity of 90% to catch the true mean of population



#Problem Six
5.29 + qt(0.25, 499) * 3.52/(500)^0.5
# 75% upper confidence interval is (5.183745, inf)


means <- numeric(500);lower = numeric(500)
for (i in 1:500) {
  x <-rgamma(500, (5/12.25)*5,5/12.25) #random sample from population with mean 5, variance 12.25
  means[i] = mean(x) #accumulate statistics about the sample mean
  #Estimate a confidence interval from Student t
  lower[i] <- mean(x) + qt(0.25, 499) * sd(x)/sqrt(500) #usually less than the true mean
  
}

mean(means)
# 5.001879

hist(means)

hist(lower)

#Quantiles for the sampling distribution of the population
qnt<-quantile(means, .25);qnt
#These are close to the mean confidence interval

sum(means < qnt[1])/500 #what fraction of the time did lower quantile lie above true mean?
0.25
sum(5 < lower)/500 #what fraction of the time did Student's confidence interval lie above the true mean?
0.246

# so we can see lower bond of one sided confidence is little bit off since the distribution is skewed. 
# so if underline distribution is not normal distribution, the t test does not work



